{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_olYU-ta3-Xv"
   },
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101628,
     "status": "ok",
     "timestamp": 1740198908768,
     "user": {
      "displayName": "lhosk",
      "userId": "12243202300103871421"
     },
     "user_tz": 300
    },
    "id": "9yXQOHU43zU5",
    "outputId": "f27d63c5-776d-4e07-8445-231d34fd5f26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (1.9.4)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from wordcloud) (1.26.4)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from wordcloud) (11.1.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from wordcloud) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install wordcloud\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import (word_tokenize,\n",
    "                           sent_tokenize,\n",
    "                           TreebankWordTokenizer,\n",
    "                           wordpunct_tokenize,\n",
    "                           TweetTokenizer,\n",
    "                           SpaceTokenizer,\n",
    "                           MWETokenizer)\n",
    "nltk.download('punkt_tab')\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "import re # Regular Expression\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import gensim.downloader as gensim_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DuGZjksz4Qna"
   },
   "source": [
    "Load the twitter set and test if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22859,
     "status": "ok",
     "timestamp": 1740198931631,
     "user": {
      "displayName": "lhosk",
      "userId": "12243202300103871421"
     },
     "user_tz": 300
    },
    "id": "q5fUX0b34SRa",
    "outputId": "815dce72-157d-4479-a2ae-7043f9c0b230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   target  1600000 non-null  int64 \n",
      " 1   ids     1600000 non-null  int64 \n",
      " 2   date    1600000 non-null  object\n",
      " 3   flag    1600000 non-null  object\n",
      " 4   user    1600000 non-null  object\n",
      " 5   text    1600000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# To load the example data set, not that you might need to change the file path to where you save the tweeter_training.csv. The data set is also avaiable on canvas for download\n",
    "tw_df = pd.read_csv('/content/drive/MyDrive/2024 Spring/Text Mining/TurnInFiles/Project1/tweeter_training.csv', encoding='ISO-8859-1', header=None)\n",
    "# Add column names\n",
    "column_names = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "tw_df.columns = column_names\n",
    "tw_df = shuffle(tw_df, random_state=24).reset_index(drop=True)\n",
    "tw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1740198931726,
     "user": {
      "displayName": "lhosk",
      "userId": "12243202300103871421"
     },
     "user_tz": 300
    },
    "id": "4zZLATfD4ZUK",
    "outputId": "7ab49b58-26f7-469c-f4e5-bf767bc3d6f0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "tw_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ec4b8b62-2b4d-4820-85c5-43ba34ff2646\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1991032647</td>\n",
       "      <td>Mon Jun 01 06:16:02 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LeilaLooo</td>\n",
       "      <td>just saw Angels and Demons last night, quality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1976257495</td>\n",
       "      <td>Sat May 30 16:56:01 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ddwalker</td>\n",
       "      <td>aaaaaaaaaaaaaand she's gone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2228371488</td>\n",
       "      <td>Thu Jun 18 14:21:27 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>PandaChanda</td>\n",
       "      <td>Getting ready to go to my high school's gradua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2176174571</td>\n",
       "      <td>Mon Jun 15 03:07:39 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElizabethChingo</td>\n",
       "      <td>Bed time. He has a name. Ryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1559252321</td>\n",
       "      <td>Sun Apr 19 10:39:39 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>drummer_dan</td>\n",
       "      <td>Senses that all is over for the quintuple chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1978951926</td>\n",
       "      <td>Sun May 31 01:03:16 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>janine_j9</td>\n",
       "      <td>@TimothyH2O theyre hellllllllllllla good! yes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>2191045455</td>\n",
       "      <td>Tue Jun 16 04:23:22 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jennyrevelle</td>\n",
       "      <td>@AdamRPhoto ...which was tiring but awesome! H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2321691453</td>\n",
       "      <td>Wed Jun 24 21:25:28 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>SallytheShizzle</td>\n",
       "      <td>@BrittGoosie yeah i wouldn't advice you to get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>2054438913</td>\n",
       "      <td>Sat Jun 06 07:21:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AlbertoConde777</td>\n",
       "      <td>Christ alone can bring lasting peace - peace w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2189574450</td>\n",
       "      <td>Tue Jun 16 00:21:38 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ilove_joe_jonas</td>\n",
       "      <td>@jonasbrothers http://twitpic.com/7gowf - LOL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>1694457405</td>\n",
       "      <td>Mon May 04 02:43:01 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Krftd</td>\n",
       "      <td>@smashingmag No worries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>2259315066</td>\n",
       "      <td>Sat Jun 20 17:22:23 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>missy_nam</td>\n",
       "      <td>Hates work wen its so nice out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>1551972176</td>\n",
       "      <td>Sat Apr 18 10:27:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sidepodcastchat</td>\n",
       "      <td>Steve Matchett has the China GP Chalk Talk up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>1754549168</td>\n",
       "      <td>Sun May 10 06:38:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>iGary</td>\n",
       "      <td>@Jamie I'm using my Highway Code book and tryi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>1770924126</td>\n",
       "      <td>Mon May 11 22:38:28 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaBianca</td>\n",
       "      <td>@victorQUEST Cool ! How long you going to be j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>1979888610</td>\n",
       "      <td>Sun May 31 04:54:37 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>JP09DisneyRocks</td>\n",
       "      <td>@mileycyrus HI  I've seen HANNAH MONTANA the M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>2177817945</td>\n",
       "      <td>Mon Jun 15 06:45:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Brightonfeed</td>\n",
       "      <td>forgot the LA Fitness #brighton is shut this w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1751911609</td>\n",
       "      <td>Sat May 09 20:34:58 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Mhikheeh</td>\n",
       "      <td>I'm on my most dramatic moment  Neveeer though...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>1974592445</td>\n",
       "      <td>Sat May 30 13:26:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>EmilyNicole14</td>\n",
       "      <td>is so glad its Saturday! Off to buy a graduati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>2222749651</td>\n",
       "      <td>Thu Jun 18 07:23:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>KillerGinger</td>\n",
       "      <td>brazil is kikin some us tail   it blows becaus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1759296133</td>\n",
       "      <td>Sun May 10 18:54:11 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>carriecc</td>\n",
       "      <td>I just heard a really loud siren go rushing by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>2001759960</td>\n",
       "      <td>Tue Jun 02 01:58:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>be_au</td>\n",
       "      <td>finally worked out the BCS theory, stoked im o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1679800681</td>\n",
       "      <td>Sat May 02 10:12:35 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>traaai</td>\n",
       "      <td>last day in Markham... last day at home...   I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>2244858079</td>\n",
       "      <td>Fri Jun 19 15:18:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tombreakincell</td>\n",
       "      <td>I didn't work...  So... I'm still waiting for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>2300059297</td>\n",
       "      <td>Tue Jun 23 13:40:56 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>NeilRobbins</td>\n",
       "      <td>@shanselman not in Europe though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec4b8b62-2b4d-4820-85c5-43ba34ff2646')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ec4b8b62-2b4d-4820-85c5-43ba34ff2646 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ec4b8b62-2b4d-4820-85c5-43ba34ff2646');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-3eaceb16-fac4-4b62-b66a-eb02adb99ea2\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3eaceb16-fac4-4b62-b66a-eb02adb99ea2')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-3eaceb16-fac4-4b62-b66a-eb02adb99ea2 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "    target         ids                          date      flag  \\\n",
       "0        0  1991032647  Mon Jun 01 06:16:02 PDT 2009  NO_QUERY   \n",
       "1        0  1976257495  Sat May 30 16:56:01 PDT 2009  NO_QUERY   \n",
       "2        0  2228371488  Thu Jun 18 14:21:27 PDT 2009  NO_QUERY   \n",
       "3        4  2176174571  Mon Jun 15 03:07:39 PDT 2009  NO_QUERY   \n",
       "4        0  1559252321  Sun Apr 19 10:39:39 PDT 2009  NO_QUERY   \n",
       "5        0  1978951926  Sun May 31 01:03:16 PDT 2009  NO_QUERY   \n",
       "6        4  2191045455  Tue Jun 16 04:23:22 PDT 2009  NO_QUERY   \n",
       "7        0  2321691453  Wed Jun 24 21:25:28 PDT 2009  NO_QUERY   \n",
       "8        4  2054438913  Sat Jun 06 07:21:13 PDT 2009  NO_QUERY   \n",
       "9        0  2189574450  Tue Jun 16 00:21:38 PDT 2009  NO_QUERY   \n",
       "10       4  1694457405  Mon May 04 02:43:01 PDT 2009  NO_QUERY   \n",
       "11       0  2259315066  Sat Jun 20 17:22:23 PDT 2009  NO_QUERY   \n",
       "12       4  1551972176  Sat Apr 18 10:27:07 PDT 2009  NO_QUERY   \n",
       "13       4  1754549168  Sun May 10 06:38:48 PDT 2009  NO_QUERY   \n",
       "14       4  1770924126  Mon May 11 22:38:28 PDT 2009  NO_QUERY   \n",
       "15       4  1979888610  Sun May 31 04:54:37 PDT 2009  NO_QUERY   \n",
       "16       0  2177817945  Mon Jun 15 06:45:07 PDT 2009  NO_QUERY   \n",
       "17       0  1751911609  Sat May 09 20:34:58 PDT 2009  NO_QUERY   \n",
       "18       4  1974592445  Sat May 30 13:26:59 PDT 2009  NO_QUERY   \n",
       "19       0  2222749651  Thu Jun 18 07:23:45 PDT 2009  NO_QUERY   \n",
       "20       0  1759296133  Sun May 10 18:54:11 PDT 2009  NO_QUERY   \n",
       "21       4  2001759960  Tue Jun 02 01:58:59 PDT 2009  NO_QUERY   \n",
       "22       0  1679800681  Sat May 02 10:12:35 PDT 2009  NO_QUERY   \n",
       "23       0  2244858079  Fri Jun 19 15:18:59 PDT 2009  NO_QUERY   \n",
       "24       0  2300059297  Tue Jun 23 13:40:56 PDT 2009  NO_QUERY   \n",
       "\n",
       "               user                                               text  \n",
       "0         LeilaLooo  just saw Angels and Demons last night, quality...  \n",
       "1          ddwalker                      aaaaaaaaaaaaaand she's gone.   \n",
       "2       PandaChanda  Getting ready to go to my high school's gradua...  \n",
       "3   ElizabethChingo                     Bed time. He has a name. Ryan   \n",
       "4       drummer_dan  Senses that all is over for the quintuple chan...  \n",
       "5         janine_j9  @TimothyH2O theyre hellllllllllllla good! yes ...  \n",
       "6      jennyrevelle  @AdamRPhoto ...which was tiring but awesome! H...  \n",
       "7   SallytheShizzle  @BrittGoosie yeah i wouldn't advice you to get...  \n",
       "8   AlbertoConde777  Christ alone can bring lasting peace - peace w...  \n",
       "9   ilove_joe_jonas  @jonasbrothers http://twitpic.com/7gowf - LOL ...  \n",
       "10            Krftd                           @smashingmag No worries   \n",
       "11        missy_nam                    Hates work wen its so nice out   \n",
       "12  sidepodcastchat  Steve Matchett has the China GP Chalk Talk up ...  \n",
       "13            iGary  @Jamie I'm using my Highway Code book and tryi...  \n",
       "14     AmandaBianca  @victorQUEST Cool ! How long you going to be j...  \n",
       "15  JP09DisneyRocks  @mileycyrus HI  I've seen HANNAH MONTANA the M...  \n",
       "16     Brightonfeed  forgot the LA Fitness #brighton is shut this w...  \n",
       "17         Mhikheeh  I'm on my most dramatic moment  Neveeer though...  \n",
       "18    EmilyNicole14  is so glad its Saturday! Off to buy a graduati...  \n",
       "19     KillerGinger  brazil is kikin some us tail   it blows becaus...  \n",
       "20         carriecc  I just heard a really loud siren go rushing by...  \n",
       "21            be_au  finally worked out the BCS theory, stoked im o...  \n",
       "22           traaai  last day in Markham... last day at home...   I...  \n",
       "23   tombreakincell  I didn't work...  So... I'm still waiting for ...  \n",
       "24      NeilRobbins                  @shanselman not in Europe though   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKMilHmq6b-B"
   },
   "source": [
    "# Make Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1740198931747,
     "user": {
      "displayName": "lhosk",
      "userId": "12243202300103871421"
     },
     "user_tz": 300
    },
    "id": "b_kmMACG6dPI"
   },
   "outputs": [],
   "source": [
    "def my_preprocessor(text):\n",
    "  \"\"\"\n",
    "  Parameters:\n",
    "    text: (str)\n",
    "\n",
    "  Changes:\n",
    "    Converts text to lowercase\n",
    "    Removed users (@_____)\n",
    "    Removed links (http_____, https______)\n",
    "    Removed numbers\n",
    "    Removed stop words (english and spanish)\n",
    "    Removed punctuation\n",
    "    Lematizes and # Corrects spelling errors\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "  # Makes text lowercase\n",
    "  text = text.lower()\n",
    "\n",
    "  # Remove users\n",
    "  text = re.sub(r'@\\w+', '', text)\n",
    "\n",
    "  # Remove links\n",
    "  text = re.sub(r'http\\S+|https\\S+', '', text)\n",
    "\n",
    "  # Remove numbers\n",
    "  text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "  # Fix spelling errors\n",
    "  # text = str(TextBlob(text).correct())\n",
    "\n",
    "  # Split text into words\n",
    "  tokens = word_tokenize(text)\n",
    "\n",
    "  # Define stop words\n",
    "  stop_words = set(stopwords.words('english')) | set(stopwords.words('spanish'))\n",
    "\n",
    "  # Removes stopwords, punctuation, contractions, and dots\n",
    "  stopunct_tokens = []\n",
    "  for token in tokens:\n",
    "    if token not in stop_words and token not in string.punctuation and token not in [\"..\", \"...\", \"....\", \".....\"]:\n",
    "            if not re.match(r\"'\\w+\", token) and not re.match(r\"n't\", token):\n",
    "                stopunct_tokens.append(token)\n",
    "\n",
    "  # Apply lemmatization\n",
    "  lemma_tokens = []\n",
    "  for token in stopunct_tokens:\n",
    "    lemma_tokens.append(lemmatizer.lemmatize(token))\n",
    "\n",
    "  # Make one string again\n",
    "  text_processed = ' '.join(lemma_tokens)\n",
    "\n",
    "  return text_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8935,
     "status": "ok",
     "timestamp": 1740198940684,
     "user": {
      "displayName": "lhosk",
      "userId": "12243202300103871421"
     },
     "user_tz": 300
    },
    "id": "KNOIXLV468Xv",
    "outputId": "2aa2d41e-9e13-486f-d461-f3dcb6021bb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time difference mean missed happy birthday anyway\n",
      "use opera\n",
      "creeping bed miss poppy pjs\n",
      "running suck chat\n",
      "awe man tan\n",
      "ewwww perforated eardrummm dr appt later ughhh\n",
      "mariner game awesome bad lost\n",
      "nine arm suck god mean\n",
      "miss year meet soon thought day milkado like pocky\n",
      "honey bee house cross-pollinating\n"
     ]
    }
   ],
   "source": [
    "# Test sample text on my_preprocessor\n",
    "sample_tw = tw_df.sample(10).text.values\n",
    "for tweet in sample_tw:\n",
    "    print(my_preprocessor(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 45885,
     "status": "ok",
     "timestamp": 1740198986571,
     "user": {
      "displayName": "lhosk",
      "userId": "12243202300103871421"
     },
     "user_tz": 300
    },
    "id": "xwVzv_VwMWjC"
   },
   "outputs": [],
   "source": [
    "# Run tweets on my_preprocessor (MAY TAKE UP TO A MINUTE)\n",
    "tweets = tw_df[\"text\"][:50000]\n",
    "labels = tw_df[\"target\"][:50000]\n",
    "processed_tweets = [my_preprocessor(tweet) for tweet in tweets]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94EjW4iMMMsv"
   },
   "source": [
    "# TF-IDF (with Naive Bayes and Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2062,
     "status": "ok",
     "timestamp": 1740198988641,
     "user": {
      "displayName": "lhosk",
      "userId": "12243202300103871421"
     },
     "user_tz": 300
    },
    "id": "2BcbYebWMLwe",
    "outputId": "a49a6ce0-6aa4-4bab-b693-81ded8588404"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "proc_tfidf = processed_tweets[:50000]\n",
    "labels_tfidf = labels[:50000]\n",
    "\n",
    "# Split the data\n",
    "tweets_train, tweets_test, y_train, y_test = train_test_split(proc_tfidf, labels_tfidf, test_size=0.2, random_state=10)\n",
    "\n",
    "# Apply TF-IDF\n",
    "vect_tfidf = TfidfVectorizer(use_idf=True)\n",
    "matr_tfidf_train = vect_tfidf.fit_transform(tweets_train)\n",
    "matr_tfidf_test  = vect_tfidf.transform(tweets_test)\n",
    "\n",
    "print(matr_tfidf_train.todense())\n",
    "print('\\n')\n",
    "print(matr_tfidf_test.todense())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMmdzDWdWFr_"
   },
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1740198988650,
     "user": {
      "displayName": "lhosk",
      "userId": "12243202300103871421"
     },
     "user_tz": 300
    },
    "id": "Vl26wC3mR1MA",
    "outputId": "dca83bdb-b5d7-4d69-96fc-cfb283a07694"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF on Naive Bayes gives 73.40%\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(matr_tfidf_train, y_train)\n",
    "model_test = model.predict(matr_tfidf_test)\n",
    "print(f'TF-IDF on Naive Bayes gives {accuracy_score(y_test, model_test)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luHrnJbplyIJ"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 181529,
     "status": "ok",
     "timestamp": 1740199170180,
     "user": {
      "displayName": "lhosk",
      "userId": "12243202300103871421"
     },
     "user_tz": 300
    },
    "id": "79Hon5bsl0g8",
    "outputId": "32499859-aa02-44a6-c1b2-dadf59fdcd7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF on Random Forest gives 73.24%\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=10, n_jobs = -1)\n",
    "model.fit(matr_tfidf_train, y_train)\n",
    "model_test = model.predict(matr_tfidf_test)\n",
    "print(f'TF-IDF on Random Forest gives {accuracy_score(y_test, model_test)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0k78rO7owqI"
   },
   "source": [
    "# Word Embedding (with Naive Bayes and Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206380,
     "status": "ok",
     "timestamp": 1740199376558,
     "user": {
      "displayName": "lhosk",
      "userId": "12243202300103871421"
     },
     "user_tz": 300
    },
    "id": "Yt2Y9yOxozUX",
    "outputId": "6893c140-7c30-42d9-aba2-b38cf55ebe3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "proc_we = processed_tweets[:50000]\n",
    "labels_we = labels[:50000]\n",
    "\n",
    "# Download pre-trained model\n",
    "pretained_word_embedding_models = list(gensim_api.info()['models'].keys())\n",
    "word_embedding_model = gensim_api.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2674,
     "status": "ok",
     "timestamp": 1740199379222,
     "user": {
      "displayName": "lhosk",
      "userId": "12243202300103871421"
     },
     "user_tz": 300
    },
    "id": "GBTwYlVYwdQH"
   },
   "outputs": [],
   "source": [
    "def embed_tweet(tweet):\n",
    "  words = tweet.split() # Already tokenized via my_preprocessor\n",
    "  word_vectors = []\n",
    "\n",
    "  for word in words:\n",
    "    if word in word_embedding_model:\n",
    "      word_vectors.append(word_embedding_model[word])\n",
    "\n",
    "  if len(word_vectors) == 0:\n",
    "    return(np.zeros(300))\n",
    "\n",
    "  return np.mean(word_vectors, axis = 0)\n",
    "\n",
    "embedded_tweets = []\n",
    "for tweet in proc_we:\n",
    "  embedded_tweets.append(embed_tweet(tweet))\n",
    "\n",
    "embedded_tweets = np.array(embedded_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 120,
     "status": "ok",
     "timestamp": 1740199379340,
     "user": {
      "displayName": "lhosk",
      "userId": "12243202300103871421"
     },
     "user_tz": 300
    },
    "id": "9QFllKsezOEk"
   },
   "outputs": [],
   "source": [
    "tweets_train, tweets_test, y_train, y_test = train_test_split(embedded_tweets, labels_we, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOzrAERzzJwE"
   },
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1740199379628,
     "user": {
      "displayName": "lhosk",
      "userId": "12243202300103871421"
     },
     "user_tz": 300
    },
    "id": "CHSZ2OHb0HQV",
    "outputId": "f09ce802-cfe9-4558-bd65-05e257a4c970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Embedding on Naive Bayes gives 60.25%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "\n",
    "# model = MultinomialNB()\n",
    "model.fit(tweets_train, y_train)\n",
    "model_test = model.predict(tweets_test)\n",
    "print(f'Word Embedding on Naive Bayes gives {accuracy_score(y_test, model_test)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffd6WrXx1AiG"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 91519,
     "status": "ok",
     "timestamp": 1740199471160,
     "user": {
      "displayName": "lhosk",
      "userId": "12243202300103871421"
     },
     "user_tz": 300
    },
    "id": "vpO3vFtT1RY8",
    "outputId": "45439644-edf8-4739-ef2c-261de9969c8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Embedding on Random Forest gives 69.39%\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=10, n_jobs = -1)\n",
    "model.fit(tweets_train, y_train)\n",
    "model_test = model.predict(tweets_test)\n",
    "print(f'Word Embedding on Random Forest gives {accuracy_score(y_test, model_test)*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNix1MCMRCDsT4AlkBON4pu",
   "collapsed_sections": [
    "_olYU-ta3-Xv",
    "fKMilHmq6b-B",
    "94EjW4iMMMsv",
    "R0k78rO7owqI",
    "qe9MmzbWoz6K"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
